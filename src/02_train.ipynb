{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from os.path import splitext\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from multiprocessing import Pool\n",
    "from functools import partial\n",
    "from tqdm.auto import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path= '../data/tiles/formatted'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(filename):\n",
    "    ext = splitext(filename)[1]\n",
    "    if ext == '.npy':\n",
    "        return Image.fromarray(np.load(filename))\n",
    "    elif ext in ['.pt', '.pth']:\n",
    "        return Image.fromarray(torch.load(filename).numpy())\n",
    "    else:\n",
    "        return Image.open(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, dataset_path) -> None:\n",
    "        files = os.listdir(dataset_path)\n",
    "        self.images_path = []\n",
    "        self.masks_path = []\n",
    "        for file in files:\n",
    "            if file.split('_')[1]=='tif':\n",
    "                self.images_path.append(os.path.join(dataset_path,file))\n",
    "                self.masks_path.append(os.path.join(dataset_path,file.replace('tif','shp')))\n",
    "                \n",
    "    def __len__(self):\n",
    "        return len(self.images_path)\n",
    "    \n",
    "    @staticmethod\n",
    "    def preprocess(mask_values, pil_img, scale, is_mask):\n",
    "        w, h = pil_img.size\n",
    "        newW, newH = int(scale * w), int(scale * h)\n",
    "        assert newW > 0 and newH > 0, 'Scale is too small, resized images would have no pixel'\n",
    "        pil_img = pil_img.resize((newW, newH), resample=Image.NEAREST if is_mask else Image.BICUBIC)\n",
    "        img = np.asarray(pil_img)\n",
    "        if img.ndim == 2:\n",
    "            img = img[np.newaxis, ...]\n",
    "        else:\n",
    "            img = img.transpose((2, 0, 1))\n",
    "        #if (img > 1).any():\n",
    "        #    img = img / 255.0\n",
    "        img = img / 255.0\n",
    "        if is_mask:\n",
    "            img = img / 255.0\n",
    "        return img\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        #return {\n",
    "        #    'image': self.images_path[idx],\n",
    "        #    'mask': self.masks_path[idx]\n",
    "        #}\n",
    "        mask = load_image(self.images_path[idx])\n",
    "        img = load_image(self.masks_path[idx])\n",
    "        img = img.convert('L')\n",
    "        \n",
    "        assert img.size == mask.size, \\\n",
    "            f'Image and mask should be the same size, but are {img.size} and {mask.size}'\n",
    "\n",
    "        self.scale = 1.0\n",
    "        #self.scale = 0.2\n",
    "        \n",
    "        img = self.preprocess(1, img, self.scale, is_mask=False)\n",
    "        mask = self.preprocess(1, mask, self.scale, is_mask=True)\n",
    "        return {\n",
    "            'image': torch.as_tensor(img.copy()).float().contiguous(),\n",
    "            'mask': torch.as_tensor(mask.copy()).long().contiguous()\n",
    "        }\n",
    "    \n",
    "class ImageNameDataset(Dataset):\n",
    "    def __init__(self, dataset_path) -> None:\n",
    "        files = os.listdir(dataset_path)\n",
    "        self.images_path = []\n",
    "        self.masks_path = []\n",
    "        for file in files:\n",
    "            if file.split('_')[1]=='tif':\n",
    "                self.images_path.append(os.path.join(dataset_path,file))\n",
    "                self.masks_path.append(os.path.join(dataset_path,file.replace('tif','shp')))\n",
    "                \n",
    "    def __len__(self):\n",
    "        return len(self.images_path)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            'image': self.images_path[idx],\n",
    "            'mask': self.masks_path[idx]\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = ImageDataset(dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12 3\n"
     ]
    }
   ],
   "source": [
    "val_percent = 0.2\n",
    "\n",
    "n_val = int(len(dataset) * val_percent)\n",
    "n_train = len(dataset) - n_val\n",
    "train_set, val_set = random_split(dataset, [n_train, n_val], generator=torch.Generator().manual_seed(0))\n",
    "\n",
    "print(len(train_set),len(val_set))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1\n",
    "#num_workers = os.cpu_count() - not working . . .\n",
    "\n",
    "loader_args = dict(batch_size=batch_size, pin_memory=True)#, num_workers=os.cpu_count(), pin_memory=True)\n",
    "train_loader = DataLoader(train_set, shuffle=True, **loader_args)\n",
    "val_loader = DataLoader(val_set, shuffle=False, **loader_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_set:\n",
      "val_set:\n",
      "torch.Size([1, 1, 250, 250])\n",
      "torch.Size([1, 1, 250, 250])\n",
      "torch.Size([1, 1, 250, 250])\n",
      "torch.Size([1, 1, 250, 250])\n",
      "torch.Size([1, 1, 250, 250])\n",
      "torch.Size([1, 1, 250, 250])\n"
     ]
    }
   ],
   "source": [
    "print('train_set:')\n",
    "for batch in train_loader:\n",
    "    #print(batch['image'].shape)\n",
    "    #print(batch['mask'].shape)\n",
    "    images, true_masks = batch['image'], batch['mask']\n",
    "    #print(images.max().item())\n",
    "    #print(true_masks.max().item())\n",
    "    \n",
    "print('val_set:')\n",
    "for batch in val_loader:\n",
    "    print(batch['image'].shape)\n",
    "    print(batch['mask'].shape)\n",
    "    images, true_masks = batch['image'], batch['mask']\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy_unet_model import UNet\n",
    "from utils.Scores import dice_loss\n",
    "import torch\n",
    "from torch import optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from src.copy_evaluate import evaluate\n",
    "from pathlib import Path\n",
    "\n",
    "model = UNet(n_channels=1, n_classes=1)\n",
    "weight_decay= 1e-8\n",
    "learning_rate= 1e-5\n",
    "amp = False\n",
    "momentum = 0.999\n",
    "epochs = 20\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "gradient_clipping: float = 1.0\n",
    "img_scale = 0.5\n",
    "save_checkpoint = True\n",
    "dir_checkpoint = '../model/checkpoints'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.RMSprop(model.parameters(),lr=learning_rate, weight_decay=weight_decay, momentum=momentum, foreach=True)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'max', patience=5)\n",
    "grad_scaler = torch.cuda.amp.GradScaler(enabled=amp)\n",
    "criterion = nn.CrossEntropyLoss() if model.n_classes > 1 else nn.BCEWithLogitsLoss()\n",
    "global_step = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(level=logging.INFO,\n",
    "                    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "                    filename='../logs/training.log',\n",
    "                    filemode='w')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1/20: 100%|██████████| 12/12 [00:32<00:00,  2.72s/img, loss (batch)=1.42]\n",
      "epoch 2/20: 100%|██████████| 12/12 [00:32<00:00,  2.68s/img, loss (batch)=1.34]\n",
      "epoch 3/20: 100%|██████████| 12/12 [00:31<00:00,  2.63s/img, loss (batch)=1.33]\n",
      "epoch 4/20: 100%|██████████| 12/12 [00:32<00:00,  2.70s/img, loss (batch)=1.33]\n",
      "epoch 5/20: 100%|██████████| 12/12 [00:32<00:00,  2.71s/img, loss (batch)=1.44]\n",
      "epoch 6/20: 100%|██████████| 12/12 [00:31<00:00,  2.63s/img, loss (batch)=1.33]\n",
      "epoch 7/20: 100%|██████████| 12/12 [00:31<00:00,  2.62s/img, loss (batch)=1.32]\n",
      "epoch 8/20: 100%|██████████| 12/12 [00:32<00:00,  2.68s/img, loss (batch)=1.32]\n",
      "epoch 9/20: 100%|██████████| 12/12 [00:31<00:00,  2.65s/img, loss (batch)=1.31]\n",
      "epoch 10/20: 100%|██████████| 12/12 [00:31<00:00,  2.63s/img, loss (batch)=1.32]\n",
      "epoch 11/20: 100%|██████████| 12/12 [00:32<00:00,  2.67s/img, loss (batch)=1.32]\n",
      "epoch 12/20: 100%|██████████| 12/12 [00:31<00:00,  2.66s/img, loss (batch)=1.32]\n",
      "epoch 13/20: 100%|██████████| 12/12 [00:31<00:00,  2.66s/img, loss (batch)=1.44]\n",
      "epoch 14/20: 100%|██████████| 12/12 [00:32<00:00,  2.70s/img, loss (batch)=1.31]\n",
      "epoch 15/20: 100%|██████████| 12/12 [00:31<00:00,  2.66s/img, loss (batch)=1.31]\n",
      "epoch 16/20: 100%|██████████| 12/12 [00:32<00:00,  2.67s/img, loss (batch)=1.32]\n",
      "epoch 17/20: 100%|██████████| 12/12 [00:32<00:00,  2.67s/img, loss (batch)=1.31]\n",
      "epoch 18/20: 100%|██████████| 12/12 [00:32<00:00,  2.69s/img, loss (batch)=1.31]\n",
      "epoch 19/20: 100%|██████████| 12/12 [00:32<00:00,  2.71s/img, loss (batch)=1.31]\n",
      "epoch 20/20: 100%|██████████| 12/12 [00:32<00:00,  2.74s/img, loss (batch)=1.31]\n"
     ]
    }
   ],
   "source": [
    "logging.info(f'''Starting training:\n",
    "        Epochs:          {epochs}\n",
    "        Batch size:      {batch_size}\n",
    "        Learning rate:   {learning_rate}\n",
    "        Training size:   {n_train}\n",
    "        Validation size: {n_val}\n",
    "        Checkpoints:     {save_checkpoint}\n",
    "        Device:          {device.type}\n",
    "        Images scaling:  {img_scale}\n",
    "        Mixed Precision: {amp}\n",
    "    ''')\n",
    "\n",
    "for epoch in range(1, epochs + 1):\n",
    "        model.train()\n",
    "        epoch_loss = 0\n",
    "        with tqdm(total=n_train, desc=f'epoch {epoch}/{epochs}', unit='img') as pbar:\n",
    "            for batch in train_loader:\n",
    "                images, true_masks = batch['image'], batch['mask']\n",
    "\n",
    "                assert images.shape[1] == model.n_channels, \\\n",
    "                    f'Network has been defined with {model.n_channels} input channels, ' \\\n",
    "                    f'but loaded images have {images.shape[1]} channels. Please check that ' \\\n",
    "                    'the images are loaded correctly.'\n",
    "\n",
    "                images = images.to(device=device, dtype=torch.float32, memory_format=torch.channels_last)\n",
    "                true_masks = true_masks.to(device=device, dtype=torch.long)\n",
    "                with torch.autocast(device.type if device.type != 'mps' else 'cpu', enabled=amp):\n",
    "                    masks_pred = model(images)\n",
    "                    \n",
    "                    if model.n_classes == 1:\n",
    "                        loss = criterion(masks_pred.squeeze(1), true_masks.squeeze(1).float())\n",
    "                        loss += dice_loss(F.sigmoid(masks_pred.squeeze(1)), true_masks.squeeze(1).float(), multiclass=False)\n",
    "\n",
    "                    else:\n",
    "                        loss = criterion(masks_pred, true_masks)\n",
    "                        loss += dice_loss(\n",
    "                            F.softmax(masks_pred, dim=1).float(),\n",
    "                            F.one_hot(true_masks, model.n_classes).permute(0, 3, 1, 2).float(),\n",
    "                            multiclass=True\n",
    "                        )\n",
    "\n",
    "                optimizer.zero_grad(set_to_none=True)\n",
    "                grad_scaler.scale(loss).backward()\n",
    "                grad_scaler.unscale_(optimizer)\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), gradient_clipping)\n",
    "                grad_scaler.step(optimizer)\n",
    "                grad_scaler.update()\n",
    "\n",
    "                pbar.update(images.shape[0])\n",
    "                global_step += 1\n",
    "                epoch_loss += loss.item()\n",
    "\n",
    "                pbar.set_postfix(**{'loss (batch)': loss.item()})\n",
    "\n",
    "                # Evaluation round\n",
    "                division_step = (n_train // (5 * batch_size))\n",
    "                if division_step > 0:\n",
    "                    if global_step % division_step == 0:\n",
    "                        \n",
    "                        val_score = evaluate(model, val_loader, device, amp)\n",
    "                        scheduler.step(val_score)\n",
    "\n",
    "                        logging.info('Validation Dice score: {}'.format(val_score))\n",
    "                        \n",
    "        if save_checkpoint:\n",
    "            Path(dir_checkpoint).mkdir(parents=True, exist_ok=True)\n",
    "            state_dict = model.state_dict()\n",
    "            #state_dict['mask_values'] = dataset.mask_values\n",
    "            torch.save(state_dict, str(dir_checkpoint +'/'+ f'checkpoint_epoch{epoch}.pth'))\n",
    "            logging.info(f'Checkpoint {epoch} saved!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_img(net,\n",
    "                full_img,\n",
    "                device,\n",
    "                scale_factor=1,\n",
    "                out_threshold=0.5):\n",
    "    net.eval()\n",
    "    img = torch.from_numpy(ImageDataset.preprocess(None, full_img, scale_factor, is_mask=False))\n",
    "    img = img.unsqueeze(0)\n",
    "    img = img.to(device=device, dtype=torch.float32)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = net(img).cpu()\n",
    "        output = F.interpolate(output, (full_img.size[1], full_img.size[0]), mode='bilinear')\n",
    "        if net.n_classes > 1:\n",
    "            mask = output.argmax(dim=1)\n",
    "        else:\n",
    "            mask = torch.sigmoid(output) > out_threshold\n",
    "\n",
    "    return mask[0].long().squeeze().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = UNet(n_channels=1, n_classes=1)\n",
    "state_dict = torch.load('../model/checkpoints/checkpoint_epoch20.pth', map_location=device)\n",
    "net.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "img = Image.open('../data/tiles/formatted/tile_shp_2_4.png')\n",
    "img = img.convert('L')\n",
    "pred = predict_img(net = net,\n",
    "                    full_img=img,\n",
    "                    scale_factor=1,\n",
    "                    out_threshold=0.5,\n",
    "                    device=device)\n",
    "\n",
    "plt.imshow(pred, cmap='gray')\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "\n",
    "mask_pil = Image.fromarray((pred * 255).astype(np.uint8))\n",
    "mask_pil.save('../results/firstpred_2_4.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.ImageProcessing import getPoints_fromPNG\n",
    "import rasterio\n",
    "from shapely.geometry import Point, box\n",
    "import geopandas as gpd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_coords = getPoints_fromPNG('../results/firstpred_2_4.png')\n",
    "            \n",
    "tif_path = '../data/tiles/original/tile_tif_2_4.tif'\n",
    "with rasterio.open(tif_path) as src:\n",
    "    transform = src.transform  #affine transformation object\n",
    "    crs = src.crs  #coordinate Reference System\n",
    "                \n",
    "geo_coords = [transform * (x, y) for x, y in image_coords]\n",
    "            \n",
    "#geo_coords -> Points (obj.)\n",
    "point_geoms = [Point(coord) for coord in geo_coords]\n",
    "    \n",
    "#create a GeoDataFrame with the Points\n",
    "gdf = gpd.GeoDataFrame(geometry=point_geoms, crs=crs)  # Adjust CRS as needed\n",
    "    \n",
    "#save the GeoDataFrame as a shapefile\n",
    "gdf.to_file('../results/firstpred_2_4.shp')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "canopysegmentation",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
