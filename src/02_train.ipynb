{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from os.path import splitext\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from multiprocessing import Pool\n",
    "from functools import partial\n",
    "from tqdm.auto import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path= '../data/tiles/formatted'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(filename):\n",
    "    ext = splitext(filename)[1]\n",
    "    if ext == '.npy':\n",
    "        return Image.fromarray(np.load(filename))\n",
    "    elif ext in ['.pt', '.pth']:\n",
    "        return Image.fromarray(torch.load(filename).numpy())\n",
    "    else:\n",
    "        return Image.open(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, dataset_path) -> None:\n",
    "        files = os.listdir(dataset_path)\n",
    "        self.images_path = []\n",
    "        self.masks_path = []\n",
    "        for file in files:\n",
    "            if file.split('_')[1]=='tif':\n",
    "                self.images_path.append(os.path.join(dataset_path,file))\n",
    "                self.masks_path.append(os.path.join(dataset_path,file.replace('tif','shp')))\n",
    "                \n",
    "    def __len__(self):\n",
    "        return len(self.images_path)\n",
    "    \n",
    "    @staticmethod\n",
    "    def preprocess(mask_values, pil_img, scale, is_mask):\n",
    "        w, h = pil_img.size\n",
    "        newW, newH = int(scale * w), int(scale * h)\n",
    "        assert newW > 0 and newH > 0, 'Scale is too small, resized images would have no pixel'\n",
    "        pil_img = pil_img.resize((newW, newH), resample=Image.NEAREST if is_mask else Image.BICUBIC)\n",
    "        img = np.asarray(pil_img)\n",
    "        if img.ndim == 2:\n",
    "            img = img[np.newaxis, ...]\n",
    "        else:\n",
    "            img = img.transpose((2, 0, 1))\n",
    "        #if (img > 1).any():\n",
    "        #    img = img / 255.0\n",
    "        img = img / 255.0\n",
    "        if is_mask:\n",
    "            img = img / 255.0\n",
    "        return img\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        #return {\n",
    "        #    'image': self.images_path[idx],\n",
    "        #    'mask': self.masks_path[idx]\n",
    "        #}\n",
    "        mask = load_image(self.images_path[idx])\n",
    "        img = load_image(self.masks_path[idx])\n",
    "        img = img.convert('L')\n",
    "        \n",
    "        assert img.size == mask.size, \\\n",
    "            f'Image and mask should be the same size, but are {img.size} and {mask.size}'\n",
    "\n",
    "        self.scale = 1.0\n",
    "        #self.scale = 0.2\n",
    "        \n",
    "        img = self.preprocess(1, img, self.scale, is_mask=False)\n",
    "        mask = self.preprocess(1, mask, self.scale, is_mask=True)\n",
    "        return {\n",
    "            'image': torch.as_tensor(img.copy()).float().contiguous(),\n",
    "            'mask': torch.as_tensor(mask.copy()).long().contiguous()\n",
    "        }\n",
    "    \n",
    "class ImageNameDataset(Dataset):\n",
    "    def __init__(self, dataset_path) -> None:\n",
    "        files = os.listdir(dataset_path)\n",
    "        self.images_path = []\n",
    "        self.masks_path = []\n",
    "        for file in files:\n",
    "            if file.split('_')[1]=='tif':\n",
    "                self.images_path.append(os.path.join(dataset_path,file))\n",
    "                self.masks_path.append(os.path.join(dataset_path,file.replace('tif','shp')))\n",
    "                \n",
    "    def __len__(self):\n",
    "        return len(self.images_path)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            'image': self.images_path[idx],\n",
    "            'mask': self.masks_path[idx]\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = ImageDataset(dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12 3\n"
     ]
    }
   ],
   "source": [
    "val_percent = 0.2\n",
    "\n",
    "n_val = int(len(dataset) * val_percent)\n",
    "n_train = len(dataset) - n_val\n",
    "train_set, val_set = random_split(dataset, [n_train, n_val], generator=torch.Generator().manual_seed(0))\n",
    "\n",
    "print(len(train_set),len(val_set))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1\n",
    "#num_workers = os.cpu_count() - not working . . .\n",
    "\n",
    "loader_args = dict(batch_size=batch_size, pin_memory=True)#, num_workers=os.cpu_count(), pin_memory=True)\n",
    "train_loader = DataLoader(train_set, shuffle=True, **loader_args)\n",
    "val_loader = DataLoader(val_set, shuffle=False, **loader_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_set:\n",
      "val_set:\n",
      "torch.Size([1, 1, 250, 250])\n",
      "torch.Size([1, 1, 250, 250])\n",
      "torch.Size([1, 1, 250, 250])\n",
      "torch.Size([1, 1, 250, 250])\n",
      "torch.Size([1, 1, 250, 250])\n",
      "torch.Size([1, 1, 250, 250])\n"
     ]
    }
   ],
   "source": [
    "print('train_set:')\n",
    "for batch in train_loader:\n",
    "    #print(batch['image'].shape)\n",
    "    #print(batch['mask'].shape)\n",
    "    images, true_masks = batch['image'], batch['mask']\n",
    "    #print(images.max().item())\n",
    "    #print(true_masks.max().item())\n",
    "    \n",
    "print('val_set:')\n",
    "for batch in val_loader:\n",
    "    print(batch['image'].shape)\n",
    "    print(batch['mask'].shape)\n",
    "    images, true_masks = batch['image'], batch['mask']\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.unet_model import UNet\n",
    "from utils.scores import dice_loss\n",
    "import torch\n",
    "from torch import optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from src.evaluate import evaluate\n",
    "from pathlib import Path\n",
    "\n",
    "model = UNet(n_channels=1, n_classes=1)\n",
    "weight_decay= 1e-8\n",
    "learning_rate= 1e-5\n",
    "amp = False\n",
    "momentum = 0.999\n",
    "epochs = 20\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "gradient_clipping: float = 1.0\n",
    "img_scale = 0.5\n",
    "save_checkpoint = True\n",
    "dir_checkpoint = '../model/checkpoints'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.RMSprop(model.parameters(),lr=learning_rate, weight_decay=weight_decay, momentum=momentum, foreach=True)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'max', patience=5)\n",
    "grad_scaler = torch.cuda.amp.GradScaler(enabled=amp)\n",
    "criterion = nn.CrossEntropyLoss() if model.n_classes > 1 else nn.BCEWithLogitsLoss()\n",
    "global_step = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(level=logging.INFO,\n",
    "                    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "                    filename='../logs/training.log',\n",
    "                    filemode='w')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1/20: 100%|██████████| 12/12 [00:38<00:00,  3.20s/img, loss (batch)=1.48]\n",
      "epoch 2/20: 100%|██████████| 12/12 [00:35<00:00,  2.99s/img, loss (batch)=1.4] \n",
      "epoch 3/20: 100%|██████████| 12/12 [00:35<00:00,  2.99s/img, loss (batch)=1.38]\n",
      "epoch 4/20: 100%|██████████| 12/12 [00:38<00:00,  3.20s/img, loss (batch)=1.37]\n",
      "epoch 5/20: 100%|██████████| 12/12 [00:44<00:00,  3.67s/img, loss (batch)=1.38]\n",
      "epoch 6/20: 100%|██████████| 12/12 [00:43<00:00,  3.59s/img, loss (batch)=1.38]\n",
      "epoch 7/20: 100%|██████████| 12/12 [00:37<00:00,  3.13s/img, loss (batch)=1.54]\n",
      "epoch 8/20: 100%|██████████| 12/12 [00:40<00:00,  3.34s/img, loss (batch)=1.38]\n",
      "epoch 9/20: 100%|██████████| 12/12 [00:59<00:00,  4.98s/img, loss (batch)=1.38]\n",
      "epoch 10/20: 100%|██████████| 12/12 [00:48<00:00,  4.04s/img, loss (batch)=1.38]\n",
      "epoch 11/20: 100%|██████████| 12/12 [00:47<00:00,  3.94s/img, loss (batch)=1.38]\n",
      "epoch 12/20: 100%|██████████| 12/12 [00:45<00:00,  3.75s/img, loss (batch)=1.38]\n",
      "epoch 13/20: 100%|██████████| 12/12 [00:43<00:00,  3.66s/img, loss (batch)=1.37]\n",
      "epoch 14/20: 100%|██████████| 12/12 [00:40<00:00,  3.41s/img, loss (batch)=1.37]\n",
      "epoch 15/20: 100%|██████████| 12/12 [00:43<00:00,  3.60s/img, loss (batch)=1.38]\n",
      "epoch 16/20: 100%|██████████| 12/12 [00:42<00:00,  3.57s/img, loss (batch)=1.38]\n",
      "epoch 17/20: 100%|██████████| 12/12 [00:55<00:00,  4.60s/img, loss (batch)=1.37]\n",
      "epoch 18/20: 100%|██████████| 12/12 [00:40<00:00,  3.38s/img, loss (batch)=1.37]\n",
      "epoch 19/20: 100%|██████████| 12/12 [00:40<00:00,  3.34s/img, loss (batch)=1.37]\n",
      "epoch 20/20: 100%|██████████| 12/12 [00:44<00:00,  3.74s/img, loss (batch)=1.37]\n"
     ]
    }
   ],
   "source": [
    "logging.info(f'''Starting training:\n",
    "        Epochs:          {epochs}\n",
    "        Batch size:      {batch_size}\n",
    "        Learning rate:   {learning_rate}\n",
    "        Training size:   {n_train}\n",
    "        Validation size: {n_val}\n",
    "        Checkpoints:     {save_checkpoint}\n",
    "        Device:          {device.type}\n",
    "        Images scaling:  {img_scale}\n",
    "        Mixed Precision: {amp}\n",
    "    ''')\n",
    "\n",
    "for epoch in range(1, epochs + 1):\n",
    "        model.train()\n",
    "        epoch_loss = 0\n",
    "        with tqdm(total=n_train, desc=f'epoch {epoch}/{epochs}', unit='img') as pbar:\n",
    "            for batch in train_loader:\n",
    "                images, true_masks = batch['image'], batch['mask']\n",
    "\n",
    "                assert images.shape[1] == model.n_channels, \\\n",
    "                    f'Network has been defined with {model.n_channels} input channels, ' \\\n",
    "                    f'but loaded images have {images.shape[1]} channels. Please check that ' \\\n",
    "                    'the images are loaded correctly.'\n",
    "\n",
    "                images = images.to(device=device, dtype=torch.float32, memory_format=torch.channels_last)\n",
    "                true_masks = true_masks.to(device=device, dtype=torch.long)\n",
    "                with torch.autocast(device.type if device.type != 'mps' else 'cpu', enabled=amp):\n",
    "                    masks_pred = model(images)\n",
    "                    \n",
    "                    if model.n_classes == 1:\n",
    "                        loss = criterion(masks_pred.squeeze(1), true_masks.squeeze(1).float())\n",
    "                        loss += dice_loss(F.sigmoid(masks_pred.squeeze(1)), true_masks.squeeze(1).float(), multiclass=False)\n",
    "\n",
    "                    else:\n",
    "                        loss = criterion(masks_pred, true_masks)\n",
    "                        loss += dice_loss(\n",
    "                            F.softmax(masks_pred, dim=1).float(),\n",
    "                            F.one_hot(true_masks, model.n_classes).permute(0, 3, 1, 2).float(),\n",
    "                            multiclass=True\n",
    "                        )\n",
    "\n",
    "                optimizer.zero_grad(set_to_none=True)\n",
    "                grad_scaler.scale(loss).backward()\n",
    "                grad_scaler.unscale_(optimizer)\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), gradient_clipping)\n",
    "                grad_scaler.step(optimizer)\n",
    "                grad_scaler.update()\n",
    "\n",
    "                pbar.update(images.shape[0])\n",
    "                global_step += 1\n",
    "                epoch_loss += loss.item()\n",
    "\n",
    "                pbar.set_postfix(**{'loss (batch)': loss.item()})\n",
    "\n",
    "                # Evaluation round\n",
    "                division_step = (n_train // (5 * batch_size))\n",
    "                if division_step > 0:\n",
    "                    if global_step % division_step == 0:\n",
    "                        \n",
    "                        val_score = evaluate(model, val_loader, device, amp)\n",
    "                        scheduler.step(val_score)\n",
    "\n",
    "                        logging.info('Validation Dice score: {}'.format(val_score))\n",
    "                        \n",
    "        if save_checkpoint:\n",
    "            Path(dir_checkpoint).mkdir(parents=True, exist_ok=True)\n",
    "            state_dict = model.state_dict()\n",
    "            #state_dict['mask_values'] = dataset.mask_values\n",
    "            torch.save(state_dict, str(dir_checkpoint +'/'+ f'checkpoint_epoch{epoch}.pth'))\n",
    "            logging.info(f'Checkpoint {epoch} saved!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_img(net,\n",
    "                full_img,\n",
    "                device,\n",
    "                scale_factor=1,\n",
    "                out_threshold=0.1):\n",
    "    net.eval()\n",
    "    img = torch.from_numpy(ImageDataset.preprocess(None, full_img, scale_factor, is_mask=False))\n",
    "    img = img.unsqueeze(0)\n",
    "    img = img.to(device=device, dtype=torch.float32)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = net(img).cpu()\n",
    "        output = F.interpolate(output, (full_img.size[1], full_img.size[0]), mode='bilinear')\n",
    "        if net.n_classes > 1:\n",
    "            mask = output.argmax(dim=1)\n",
    "        else:\n",
    "            mask = torch.sigmoid(output) > out_threshold\n",
    "\n",
    "    return mask[0].long().squeeze().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = UNet(n_channels=1, n_classes=1)\n",
    "state_dict = torch.load('../model/checkpoints/checkpoint_epoch20.pth', map_location=device)\n",
    "net.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "img = Image.open('../data/tiles/formatted/tile_shp_2_4.png')\n",
    "img = img.convert('L')\n",
    "pred = predict_img(net = net,\n",
    "                    full_img=img,\n",
    "                    scale_factor=1,\n",
    "                    out_threshold=0.5,\n",
    "                    device=device)\n",
    "\n",
    "plt.imshow(pred, cmap='gray')\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "\n",
    "mask_pil = Image.fromarray((pred * 255).astype(np.uint8))\n",
    "mask_pil.save('../results/firstpred_2_4.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.imageprocessing import getPoints_fromPNG, convert_PNGtoSHP\n",
    "import rasterio\n",
    "from shapely.geometry import Point, box\n",
    "import geopandas as gpd\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "file = 'tile_tif_1_0.png'\n",
    "#img = Image.open(os.path.join('../data/tiles/formatted',file)).convert('L')\n",
    "\n",
    "img = cv2.imread(os.path.join('../data/tiles/formatted',file))\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "img = Image.fromarray(img).convert('L')\n",
    "#img = img.point(lambda p: p > threshold and 255)\n",
    "#print(np.array(img))\n",
    "#plt.imshow(img)\n",
    "#plt.axis('off')\n",
    "#plt.show()\n",
    "img.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction(unet,folder, out_folder):\n",
    "    threshold = 254\n",
    "    files = os.listdir(folder)\n",
    "    for file in files:\n",
    "        if file.split('_')[1]=='tif':\n",
    "            print(file)\n",
    "            #img = Image.open(os.path.join(folder,file)).convert('L')\n",
    "            #img = img.point(lambda p: p > threshold and 255)\n",
    "            img = cv2.imread(os.path.join(folder,file))\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            img = Image.fromarray(img).convert('L')\n",
    "            #img.show()\n",
    "            pred = predict_img(net = unet,\n",
    "                    full_img=img,\n",
    "                    scale_factor=1,\n",
    "                    out_threshold=0.8,\n",
    "                    device=device)\n",
    "            mask = Image.fromarray((pred * 255).astype(np.uint8))\n",
    "            tile, type, row, col = splitext(file)[0].split('_')\n",
    "            mask_filename = f'pred_{tile}_png_{row}_{col}.png'\n",
    "            mask.save(os.path.join(out_folder,mask_filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tile_tif_0_2.png\n",
      "tile_tif_2_0.png\n",
      "tile_tif_2_1.png\n",
      "tile_tif_0_3.png\n",
      "tile_tif_0_1.png\n",
      "tile_tif_2_3.png\n",
      "tile_tif_2_2.png\n",
      "tile_tif_0_0.png\n",
      "tile_tif_0_4.png\n",
      "tile_tif_2_4.png\n",
      "tile_tif_1_1.png\n",
      "tile_tif_1_0.png\n",
      "tile_tif_1_2.png\n",
      "tile_tif_1_3.png\n",
      "tile_tif_1_4.png\n"
     ]
    }
   ],
   "source": [
    "prediction(net,\n",
    "           '../data/tiles/formatted',\n",
    "           '../results')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_PNGtoSHP('../data/tiles/original')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_coords = getPoints_fromPNG('../results/firstpred_2_4.png')\n",
    "            \n",
    "tif_path = '../data/tiles/original/tile_tif_2_4.tif'\n",
    "with rasterio.open(tif_path) as src:\n",
    "    transform = src.transform  #affine transformation object\n",
    "    crs = src.crs  #coordinate Reference System\n",
    "                \n",
    "geo_coords = [transform * (x, y) for x, y in image_coords]\n",
    "            \n",
    "#geo_coords -> Points (obj.)\n",
    "point_geoms = [Point(coord) for coord in geo_coords]\n",
    "    \n",
    "#create a GeoDataFrame with the Points\n",
    "gdf = gpd.GeoDataFrame(geometry=point_geoms, crs=crs)  # Adjust CRS as needed\n",
    "    \n",
    "#save the GeoDataFrame as a shapefile\n",
    "gdf.to_file('../results/firstpred_2_4.shp')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "canopysegmentation",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
