{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e7e3165a-73b9-429c-a179-ad6a96272b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "import argparse\n",
    "import logging\n",
    "import os\n",
    "import random\n",
    "import sys\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.transforms.functional as TF\n",
    "from pathlib import Path\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from tqdm import tqdm\n",
    "\n",
    "import wandb\n",
    "from evaluate import evaluate\n",
    "from unet import UNet\n",
    "#from utils.data_loading import BasicDataset, CarvanaDataset\n",
    "from utils.datasets import ImageDataset\n",
    "from utils.dice_score import dice_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5138709e-6768-436d-8406-d03826da991f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_img = Path('./data/2024-04-13-dataset/augmentated/train/images')\n",
    "dir_mask = Path('./data/2024-04-13-dataset/augmentated/train/masks')\n",
    "dir_checkpoint = Path('./model/checkpoints/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5860740d-dbd2-479b-a19b-b5d116838d63",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "UNet.__init__() got an unexpected keyword argument 'channels'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mUNet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchannels\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclasses\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m device \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      3\u001b[0m epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5\u001b[39m\n",
      "\u001b[0;31mTypeError\u001b[0m: UNet.__init__() got an unexpected keyword argument 'channels'"
     ]
    }
   ],
   "source": [
    "model = UNet(channels = 3, classes = 1)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "epochs = 5\n",
    "batch_size = 1\n",
    "learning_rate = 1e-5\n",
    "val_percent = 0.1\n",
    "save_checkpoint = True\n",
    "img_scale = 0.5\n",
    "amp = False\n",
    "weight_decay = 1e-8\n",
    "momentum = 0.999\n",
    "gradient_clipping = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a60cd71-0d40-43b3-a9a9-a9a861649df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(\n",
    "        model,\n",
    "        device,\n",
    "        epochs: int = 5,\n",
    "        batch_size: int = 1,\n",
    "        learning_rate: float = 1e-5,\n",
    "        val_percent: float = 0.1,\n",
    "        save_checkpoint: bool = True,\n",
    "        img_scale: float = 0.5,\n",
    "        amp: bool = False,\n",
    "        weight_decay: float = 1e-8,\n",
    "        momentum: float = 0.999,\n",
    "        gradient_clipping: float = 1.0,\n",
    "):\n",
    "    # 1. Create dataset\n",
    "    #try:\n",
    "    #    dataset = CarvanaDataset(dir_img, dir_mask, img_scale)\n",
    "    #except (AssertionError, RuntimeError, IndexError):\n",
    "    #    dataset = BasicDataset(dir_img, dir_mask, img_scale)\n",
    "\n",
    "    dataset = ImageDataset('../data/2024-04-13-dataset/augmentated/train')\n",
    "\n",
    "    # 2. Split into train / validation partitions\n",
    "    n_val = int(len(dataset) * val_percent)\n",
    "    n_train = len(dataset) - n_val\n",
    "    train_set, val_set = random_split(dataset, [n_train, n_val], generator=torch.Generator().manual_seed(0))\n",
    "\n",
    "    # 3. Create data loaders\n",
    "    loader_args = dict(batch_size=batch_size, num_workers=os.cpu_count(), pin_memory=True)\n",
    "    train_loader = DataLoader(train_set, shuffle=True, **loader_args)\n",
    "    val_loader = DataLoader(val_set, shuffle=False, drop_last=True, **loader_args)\n",
    "\n",
    "    # (Initialize logging)\n",
    "    experiment = wandb.init(project='U-Net', resume='allow', anonymous='must')\n",
    "    experiment.config.update(\n",
    "        dict(epochs=epochs, batch_size=batch_size, learning_rate=learning_rate,\n",
    "             val_percent=val_percent, save_checkpoint=save_checkpoint, img_scale=img_scale, amp=amp)\n",
    "    )\n",
    "\n",
    "    logging.info(f'''Starting training:\n",
    "        Epochs:          {epochs}\n",
    "        Batch size:      {batch_size}\n",
    "        Learning rate:   {learning_rate}\n",
    "        Training size:   {n_train}\n",
    "        Validation size: {n_val}\n",
    "        Checkpoints:     {save_checkpoint}\n",
    "        Device:          {device.type}\n",
    "        Images scaling:  {img_scale}\n",
    "        Mixed Precision: {amp}\n",
    "    ''')\n",
    "\n",
    "    # 4. Set up the optimizer, the loss, the learning rate scheduler and the loss scaling for AMP\n",
    "    optimizer = optim.RMSprop(model.parameters(),\n",
    "                              lr=learning_rate, weight_decay=weight_decay, momentum=momentum, foreach=True)\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'max', patience=5)  # goal: maximize Dice score\n",
    "    grad_scaler = torch.cuda.amp.GradScaler(enabled=amp)\n",
    "    criterion = nn.CrossEntropyLoss() if model.n_classes > 1 else nn.BCEWithLogitsLoss()\n",
    "    global_step = 0\n",
    "\n",
    "    # 5. Begin training\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        model.train()\n",
    "        epoch_loss = 0\n",
    "        with tqdm(total=n_train, desc=f'Epoch {epoch}/{epochs}', unit='img') as pbar:\n",
    "            for batch in train_loader:\n",
    "                images, true_masks = batch['image'], batch['mask']\n",
    "\n",
    "                assert images.shape[1] == model.n_channels, \\\n",
    "                    f'Network has been defined with {model.n_channels} input channels, ' \\\n",
    "                    f'but loaded images have {images.shape[1]} channels. Please check that ' \\\n",
    "                    'the images are loaded correctly.'\n",
    "\n",
    "                images = images.to(device=device, dtype=torch.float32, memory_format=torch.channels_last)\n",
    "                true_masks = true_masks.to(device=device, dtype=torch.long)\n",
    "\n",
    "                with torch.autocast(device.type if device.type != 'mps' else 'cpu', enabled=amp):\n",
    "                    masks_pred = model(images)\n",
    "                    if model.n_classes == 1:\n",
    "                        loss = criterion(masks_pred.squeeze(1), true_masks.float())\n",
    "                        loss += dice_loss(F.sigmoid(masks_pred.squeeze(1)), true_masks.float(), multiclass=False)\n",
    "                    else:\n",
    "                        loss = criterion(masks_pred, true_masks)\n",
    "                        loss += dice_loss(\n",
    "                            F.softmax(masks_pred, dim=1).float(),\n",
    "                            F.one_hot(true_masks, model.n_classes).permute(0, 3, 1, 2).float(),\n",
    "                            multiclass=True\n",
    "                        )\n",
    "\n",
    "                optimizer.zero_grad(set_to_none=True)\n",
    "                grad_scaler.scale(loss).backward()\n",
    "                grad_scaler.unscale_(optimizer)\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), gradient_clipping)\n",
    "                grad_scaler.step(optimizer)\n",
    "                grad_scaler.update()\n",
    "\n",
    "                pbar.update(images.shape[0])\n",
    "                global_step += 1\n",
    "                epoch_loss += loss.item()\n",
    "                experiment.log({\n",
    "                    'train loss': loss.item(),\n",
    "                    'step': global_step,\n",
    "                    'epoch': epoch\n",
    "                })\n",
    "                pbar.set_postfix(**{'loss (batch)': loss.item()})\n",
    "\n",
    "                # Evaluation round\n",
    "                division_step = (n_train // (5 * batch_size))\n",
    "                if division_step > 0:\n",
    "                    if global_step % division_step == 0:\n",
    "                        histograms = {}\n",
    "                        for tag, value in model.named_parameters():\n",
    "                            tag = tag.replace('/', '.')\n",
    "                            if not (torch.isinf(value) | torch.isnan(value)).any():\n",
    "                                histograms['Weights/' + tag] = wandb.Histogram(value.data.cpu())\n",
    "                            if not (torch.isinf(value.grad) | torch.isnan(value.grad)).any():\n",
    "                                histograms['Gradients/' + tag] = wandb.Histogram(value.grad.data.cpu())\n",
    "\n",
    "                        val_score = evaluate(model, val_loader, device, amp)\n",
    "                        scheduler.step(val_score)\n",
    "\n",
    "                        logging.info('Validation Dice score: {}'.format(val_score))\n",
    "                        try:\n",
    "                            experiment.log({\n",
    "                                'learning rate': optimizer.param_groups[0]['lr'],\n",
    "                                'validation Dice': val_score,\n",
    "                                'images': wandb.Image(images[0].cpu()),\n",
    "                                'masks': {\n",
    "                                    'true': wandb.Image(true_masks[0].float().cpu()),\n",
    "                                    'pred': wandb.Image(masks_pred.argmax(dim=1)[0].float().cpu()),\n",
    "                                },\n",
    "                                'step': global_step,\n",
    "                                'epoch': epoch,\n",
    "                                **histograms\n",
    "                            })\n",
    "                        except:\n",
    "                            pass\n",
    "\n",
    "        if save_checkpoint:\n",
    "            Path(dir_checkpoint).mkdir(parents=True, exist_ok=True)\n",
    "            state_dict = model.state_dict()\n",
    "            state_dict['mask_values'] = dataset.mask_values\n",
    "            torch.save(state_dict, str(dir_checkpoint / 'checkpoint_epoch{}.pth'.format(epoch)))\n",
    "            logging.info(f'Checkpoint {epoch} saved!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1e8feea2-2610-440e-9f2e-2d2ec4d62c4e",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def get_args():\n",
    "    parser = argparse.ArgumentParser(description='Train the UNet on images and target masks')\n",
    "    parser.add_argument('--epochs', '-e', metavar='E', type=int, default=5, help='Number of epochs')\n",
    "    parser.add_argument('--batch-size', '-b', dest='batch_size', metavar='B', type=int, default=1, help='Batch size')\n",
    "    parser.add_argument('--learning-rate', '-l', metavar='LR', type=float, default=1e-5,\n",
    "                        help='Learning rate', dest='lr')\n",
    "    parser.add_argument('--load', '-f', type=str, default=False, help='Load model from a .pth file')\n",
    "    parser.add_argument('--scale', '-s', type=float, default=0.5, help='Downscaling factor of the images')\n",
    "    parser.add_argument('--validation', '-v', dest='val', type=float, default=10.0,\n",
    "                        help='Percent of the data that is used as validation (0-100)')\n",
    "    parser.add_argument('--amp', action='store_true', default=False, help='Use mixed precision')\n",
    "    parser.add_argument('--bilinear', action='store_true', default=False, help='Use bilinear upsampling')\n",
    "    parser.add_argument('--classes', '-c', type=int, default=2, help='Number of classes')\n",
    "\n",
    "    return parser.parse_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6c4fdfd7-d965-405a-90b1-543b7c09a154",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = 2\n",
    "bilinear = False\n",
    "load = False\n",
    "epochs = 5\n",
    "batch_size = 1\n",
    "lr = 1e-5\n",
    "scale = 1\n",
    "val = 0.1\n",
    "amp = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65ee90f3-fb26-4570-aca8-da5c867da7eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Using device cuda\n",
      "INFO: Network:\n",
      "\t3 input channels\n",
      "\t2 output channels (classes)\n",
      "\tTransposed conv upscaling\n",
      "/home/ubuntu/miniconda3/lib/python3.12/site-packages/torch/cuda/__init__.py:628: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mbanoczymartin\u001b[0m (\u001b[33mpoltextlab\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/ubuntu/banoczymartin_thesis/TreeDetection/src/wandb/run-20240414_151310-ef6rjs2w</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/poltextlab/U-Net/runs/ef6rjs2w' target=\"_blank\">zesty-sea-10</a></strong> to <a href='https://wandb.ai/poltextlab/U-Net' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/poltextlab/U-Net' target=\"_blank\">https://wandb.ai/poltextlab/U-Net</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/poltextlab/U-Net/runs/ef6rjs2w' target=\"_blank\">https://wandb.ai/poltextlab/U-Net/runs/ef6rjs2w</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Starting training:\n",
      "        Epochs:          5\n",
      "        Batch size:      1\n",
      "        Learning rate:   1e-05\n",
      "        Training size:   6786\n",
      "        Validation size: 6\n",
      "        Checkpoints:     True\n",
      "        Device:          cuda\n",
      "        Images scaling:  1\n",
      "        Mixed Precision: False\n",
      "    \n",
      "Epoch 1/5:  20%|█▏    | 1357/6786 [00:32<02:09, 42.01img/s, loss (batch)=0.0564]\n",
      "Validation round:   0%|                                | 0/6 [00:00<?, ?batch/s]\u001b[A\n",
      "Validation round:  17%|████                    | 1/6 [00:00<00:02,  1.85batch/s]\u001b[A\n",
      "                                                                                \u001b[AINFO: Validation Dice score: 2.0592789695683678e-09\n",
      "Epoch 1/5:  40%|██▍   | 2714/6786 [01:06<01:35, 42.66img/s, loss (batch)=0.0549]\n",
      "Validation round:   0%|                                | 0/6 [00:00<?, ?batch/s]\u001b[A\n",
      "Validation round:  17%|████                    | 1/6 [00:00<00:01,  2.66batch/s]\u001b[A\n",
      "                                                                                \u001b[AINFO: Validation Dice score: 0.2883129119873047\n",
      "Epoch 1/5:  60%|███▌  | 4071/6786 [01:39<01:05, 41.73img/s, loss (batch)=0.0609]\n",
      "Validation round:   0%|                                | 0/6 [00:00<?, ?batch/s]\u001b[A\n",
      "Validation round:  17%|████                    | 1/6 [00:00<00:01,  2.60batch/s]\u001b[A\n",
      "                                                                                \u001b[AINFO: Validation Dice score: 0.24883514642715454\n",
      "Epoch 1/5:  80%|████▊ | 5428/6786 [02:12<00:32, 41.25img/s, loss (batch)=0.0233]\n",
      "Validation round:   0%|                                | 0/6 [00:00<?, ?batch/s]\u001b[A\n",
      "Validation round:  17%|████                    | 1/6 [00:00<00:01,  2.54batch/s]\u001b[A\n",
      "                                                                                \u001b[AINFO: Validation Dice score: 0.4497641324996948\n",
      "Epoch 1/5: 100%|█████▉| 6785/6786 [02:45<00:00, 46.80img/s, loss (batch)=0.0541]\n",
      "Validation round:   0%|                                | 0/6 [00:00<?, ?batch/s]\u001b[A\n",
      "Validation round:  17%|████                    | 1/6 [00:00<00:02,  1.85batch/s]\u001b[A\n",
      "                                                                                \u001b[AINFO: Validation Dice score: 0.2088552713394165\n",
      "Epoch 1/5: 100%|██████| 6786/6786 [02:46<00:00, 40.69img/s, loss (batch)=0.0404]\n",
      "INFO: Checkpoint 1 saved!\n",
      "Epoch 2/5:  20%|█▍     | 1356/6786 [00:31<02:04, 43.53img/s, loss (batch)=0.194]\n",
      "Validation round:   0%|                                | 0/6 [00:00<?, ?batch/s]\u001b[A\n",
      "Validation round:  17%|████                    | 1/6 [00:00<00:02,  1.81batch/s]\u001b[A\n",
      "                                                                                \u001b[AINFO: Validation Dice score: 0.5092754364013672\n",
      "Epoch 2/5:  40%|██▍   | 2713/6786 [01:04<01:35, 42.47img/s, loss (batch)=0.0517]\n",
      "Validation round:   0%|                                | 0/6 [00:00<?, ?batch/s]\u001b[A\n",
      "Validation round:  17%|████                    | 1/6 [00:00<00:02,  2.43batch/s]\u001b[A\n",
      "                                                                                \u001b[AINFO: Validation Dice score: 0.3427407145500183\n",
      "Epoch 2/5:  60%|████▊   | 4070/6786 [01:37<01:02, 43.71img/s, loss (batch)=0.04]\n",
      "Validation round:   0%|                                | 0/6 [00:00<?, ?batch/s]\u001b[A\n",
      "Validation round:  17%|████                    | 1/6 [00:00<00:02,  1.89batch/s]\u001b[A\n",
      "                                                                                \u001b[AINFO: Validation Dice score: 0.13679225742816925\n",
      "Epoch 2/5:  80%|████▊ | 5427/6786 [02:11<00:30, 43.90img/s, loss (batch)=0.0602]\n",
      "Validation round:   0%|                                | 0/6 [00:00<?, ?batch/s]\u001b[A\n",
      "Validation round:  17%|████                    | 1/6 [00:00<00:02,  1.90batch/s]\u001b[A\n",
      "                                                                                \u001b[AINFO: Validation Dice score: 0.264434814453125\n",
      "Epoch 2/5: 100%|█████▉| 6784/6786 [02:44<00:00, 48.81img/s, loss (batch)=0.0404]\n",
      "Validation round:   0%|                                | 0/6 [00:00<?, ?batch/s]\u001b[A\n",
      "Validation round:  17%|████                    | 1/6 [00:00<00:02,  1.71batch/s]\u001b[A\n",
      "                                                                                \u001b[AINFO: Validation Dice score: 0.40933817625045776\n",
      "Epoch 2/5: 100%|████████| 6786/6786 [02:46<00:00, 40.82img/s, loss (batch)=0.12]\n",
      "INFO: Checkpoint 2 saved!\n",
      "Epoch 3/5:  20%|█▏    | 1355/6786 [00:32<02:05, 43.42img/s, loss (batch)=0.0732]\n",
      "Validation round:   0%|                                | 0/6 [00:00<?, ?batch/s]\u001b[A\n",
      "Validation round:  17%|████                    | 1/6 [00:00<00:02,  2.46batch/s]\u001b[A\n",
      "                                                                                \u001b[AINFO: Validation Dice score: 0.20022457838058472\n",
      "Epoch 3/5:  40%|██▍   | 2712/6786 [01:05<01:21, 49.86img/s, loss (batch)=0.0515]\n",
      "Validation round:   0%|                                | 0/6 [00:00<?, ?batch/s]\u001b[A\n",
      "Validation round:  17%|████                    | 1/6 [00:00<00:01,  2.63batch/s]\u001b[A\n",
      "                                                                                \u001b[AINFO: Validation Dice score: 0.12446457147598267\n",
      "Epoch 3/5:  60%|███▌  | 4069/6786 [01:37<01:03, 42.57img/s, loss (batch)=0.0305]\n",
      "Validation round:   0%|                                | 0/6 [00:00<?, ?batch/s]\u001b[A\n",
      "Validation round:  17%|████                    | 1/6 [00:00<00:01,  2.59batch/s]\u001b[A\n",
      "                                                                                \u001b[AINFO: Validation Dice score: 0.3323018252849579\n",
      "Epoch 3/5:  80%|████▊ | 5426/6786 [02:10<00:28, 48.46img/s, loss (batch)=0.0431]\n",
      "Validation round:   0%|                                | 0/6 [00:00<?, ?batch/s]\u001b[A\n",
      "Validation round:  17%|████                    | 1/6 [00:00<00:01,  2.52batch/s]\u001b[A\n",
      "                                                                                \u001b[AINFO: Validation Dice score: 0.3856857419013977\n",
      "Epoch 3/5: 100%|██████▉| 6783/6786 [02:43<00:00, 44.08img/s, loss (batch)=0.086]\n",
      "Validation round:   0%|                                | 0/6 [00:00<?, ?batch/s]\u001b[A\n",
      "Validation round:  17%|████                    | 1/6 [00:00<00:02,  1.87batch/s]\u001b[A\n",
      "                                                                                \u001b[AINFO: Validation Dice score: 0.5374054908752441\n",
      "Epoch 3/5: 100%|███████| 6786/6786 [02:45<00:00, 41.07img/s, loss (batch)=0.072]\n",
      "INFO: Checkpoint 3 saved!\n",
      "Epoch 4/5:  20%|█▏    | 1354/6786 [00:32<02:13, 40.81img/s, loss (batch)=0.0319]\n",
      "Validation round:   0%|                                | 0/6 [00:00<?, ?batch/s]\u001b[A\n",
      "Validation round:  17%|████                    | 1/6 [00:00<00:02,  1.87batch/s]\u001b[A\n",
      "                                                                                \u001b[AINFO: Validation Dice score: 0.22158853709697723\n",
      "Epoch 4/5:  32%|█▉    | 2171/6786 [00:53<01:56, 39.66img/s, loss (batch)=0.0778]"
     ]
    }
   ],
   "source": [
    "logging.basicConfig(level=logging.INFO, format='%(levelname)s: %(message)s')\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "logging.info(f'Using device {device}')\n",
    "\n",
    "# Change here to adapt to your data\n",
    "# n_channels=3 for RGB images\n",
    "# n_classes is the number of probabilities you want to get per pixel\n",
    "model = UNet(n_channels=3, n_classes=classes, bilinear=bilinear)\n",
    "model = model.to(memory_format=torch.channels_last)\n",
    "\n",
    "logging.info(f'Network:\\n'\n",
    "                 f'\\t{model.n_channels} input channels\\n'\n",
    "                 f'\\t{model.n_classes} output channels (classes)\\n'\n",
    "                 f'\\t{\"Bilinear\" if model.bilinear else \"Transposed conv\"} upscaling')\n",
    "\n",
    "if load:\n",
    "    state_dict = torch.load(load, map_location=device)\n",
    "    del state_dict['mask_values']\n",
    "    model.load_state_dict(state_dict)\n",
    "    logging.info(f'Model loaded from {load}')\n",
    "\n",
    "model.to(device=device)\n",
    "try:\n",
    "    train_model(\n",
    "        model=model,\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size,\n",
    "        learning_rate=lr,\n",
    "        device=device,\n",
    "        img_scale=scale,\n",
    "        val_percent=val / 100,\n",
    "        amp=amp\n",
    "    )\n",
    "except torch.cuda.OutOfMemoryError:\n",
    "    logging.error('Detected OutOfMemoryError! '\n",
    "                  'Enabling checkpointing to reduce memory usage, but this slows down training. '\n",
    "                  'Consider enabling AMP (--amp) for fast and memory efficient training')\n",
    "    torch.cuda.empty_cache()\n",
    "    model.use_checkpointing()\n",
    "    train_model(\n",
    "        model=model,\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size,\n",
    "        learning_rate=lr,\n",
    "        device=device,\n",
    "        img_scale=scale,\n",
    "        val_percent=val / 100,\n",
    "        amp=amp\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fe4f53c-67e2-4947-ba72-0b7f60906fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = get_args()\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, format='%(levelname)s: %(message)s')\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "logging.info(f'Using device {device}')\n",
    "\n",
    "# Change here to adapt to your data\n",
    "# n_channels=3 for RGB images\n",
    "# n_classes is the number of probabilities you want to get per pixel\n",
    "model = UNet(n_channels=3, n_classes=args.classes, bilinear=args.bilinear)\n",
    "model = model.to(memory_format=torch.channels_last)\n",
    "\n",
    "logging.info(f'Network:\\n'\n",
    "                 f'\\t{model.n_channels} input channels\\n'\n",
    "                 f'\\t{model.n_classes} output channels (classes)\\n'\n",
    "                 f'\\t{\"Bilinear\" if model.bilinear else \"Transposed conv\"} upscaling')\n",
    "\n",
    "if args.load:\n",
    "    state_dict = torch.load(args.load, map_location=device)\n",
    "    del state_dict['mask_values']\n",
    "    model.load_state_dict(state_dict)\n",
    "    logging.info(f'Model loaded from {args.load}')\n",
    "\n",
    "model.to(device=device)\n",
    "try:\n",
    "    train_model(\n",
    "        model=model,\n",
    "        epochs=args.epochs,\n",
    "        batch_size=args.batch_size,\n",
    "        learning_rate=args.lr,\n",
    "        device=device,\n",
    "        img_scale=args.scale,\n",
    "        val_percent=args.val / 100,\n",
    "        amp=args.amp\n",
    "    )\n",
    "except torch.cuda.OutOfMemoryError:\n",
    "    logging.error('Detected OutOfMemoryError! '\n",
    "                  'Enabling checkpointing to reduce memory usage, but this slows down training. '\n",
    "                  'Consider enabling AMP (--amp) for fast and memory efficient training')\n",
    "    torch.cuda.empty_cache()\n",
    "    model.use_checkpointing()\n",
    "    train_model(\n",
    "        model=model,\n",
    "        epochs=args.epochs,\n",
    "        batch_size=args.batch_size,\n",
    "        learning_rate=args.lr,\n",
    "        device=device,\n",
    "        img_scale=args.scale,\n",
    "        val_percent=args.val / 100,\n",
    "        amp=args.amp\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
